{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing in the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the MNIST dataset and preprocessing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = transforms.Compose([\n",
    "    transforms.Grayscale(3),  # Convert to 3 channels for ResNet-50\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, transform=mnist_transform, download=True)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, transform=mnist_transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet 50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "BaseModel                                     [64, 10]                  --\n",
       "├─ResNet: 1-1                                 [64, 10]                  --\n",
       "│    └─Conv2d: 2-1                            [64, 64, 112, 112]        9,408\n",
       "│    └─BatchNorm2d: 2-2                       [64, 64, 112, 112]        128\n",
       "│    └─ReLU: 2-3                              [64, 64, 112, 112]        --\n",
       "│    └─MaxPool2d: 2-4                         [64, 64, 56, 56]          --\n",
       "│    └─Sequential: 2-5                        [64, 256, 56, 56]         --\n",
       "│    │    └─Bottleneck: 3-1                   [64, 256, 56, 56]         75,008\n",
       "│    │    └─Bottleneck: 3-2                   [64, 256, 56, 56]         70,400\n",
       "│    │    └─Bottleneck: 3-3                   [64, 256, 56, 56]         70,400\n",
       "│    └─Sequential: 2-6                        [64, 512, 28, 28]         --\n",
       "│    │    └─Bottleneck: 3-4                   [64, 512, 28, 28]         379,392\n",
       "│    │    └─Bottleneck: 3-5                   [64, 512, 28, 28]         280,064\n",
       "│    │    └─Bottleneck: 3-6                   [64, 512, 28, 28]         280,064\n",
       "│    │    └─Bottleneck: 3-7                   [64, 512, 28, 28]         280,064\n",
       "│    └─Sequential: 2-7                        [64, 1024, 14, 14]        --\n",
       "│    │    └─Bottleneck: 3-8                   [64, 1024, 14, 14]        1,512,448\n",
       "│    │    └─Bottleneck: 3-9                   [64, 1024, 14, 14]        1,117,184\n",
       "│    │    └─Bottleneck: 3-10                  [64, 1024, 14, 14]        1,117,184\n",
       "│    │    └─Bottleneck: 3-11                  [64, 1024, 14, 14]        1,117,184\n",
       "│    │    └─Bottleneck: 3-12                  [64, 1024, 14, 14]        1,117,184\n",
       "│    │    └─Bottleneck: 3-13                  [64, 1024, 14, 14]        1,117,184\n",
       "│    └─Sequential: 2-8                        [64, 2048, 7, 7]          --\n",
       "│    │    └─Bottleneck: 3-14                  [64, 2048, 7, 7]          6,039,552\n",
       "│    │    └─Bottleneck: 3-15                  [64, 2048, 7, 7]          4,462,592\n",
       "│    │    └─Bottleneck: 3-16                  [64, 2048, 7, 7]          4,462,592\n",
       "│    └─AdaptiveAvgPool2d: 2-9                 [64, 2048, 1, 1]          --\n",
       "│    └─Linear: 2-10                           [64, 10]                  20,490\n",
       "===============================================================================================\n",
       "Total params: 23,528,522\n",
       "Trainable params: 23,528,522\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 261.58\n",
       "===============================================================================================\n",
       "Input size (MB): 38.54\n",
       "Forward/backward pass size (MB): 11380.72\n",
       "Params size (MB): 94.11\n",
       "Estimated Total Size (MB): 11513.37\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                n_class : int = 31):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.n_class = n_class\n",
    "        self.model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "        n_features = self.model.fc.in_features\n",
    "        fc = torch.nn.Linear(n_features, n_class)\n",
    "        self.model.fc = fc\n",
    "        self.model.fc.weight.data.normal_(0, 0.005)\n",
    "        self.model.fc.bias.data.fill_(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "# Testing the Base\n",
    "num_classes = 10\n",
    "test_model = BaseModel(n_class=num_classes)\n",
    "\n",
    "test_model.to(device)\n",
    "\n",
    "summary(test_model, input_size=(64,3,224,224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy Calculation Function\n",
    "def calculate_entropy(logits):\n",
    "    \"\"\"\n",
    "    Calculates entropy from logits.\n",
    "    Entropy = -Σ(p(x) * log(p(x)))\n",
    "    \"\"\"\n",
    "    probabilities = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    log_probabilities = F.log_softmax(logits, dim=1)\n",
    "    entropy = -torch.sum(probabilities * log_probabilities, dim=1)  # Entropy for each sample\n",
    "    return entropy\n",
    "\n",
    "# # Training Function\n",
    "# def train_model(model, dataloader, optimizer, criterion, device):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     correct = 0\n",
    "#     total_samples = 0\n",
    "\n",
    "#     for images, labels in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "\n",
    "#         # Backward pass\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Metrics\n",
    "#         total_loss += loss.item()\n",
    "#         _, preds = torch.max(outputs, dim=1)\n",
    "#         correct += (preds == labels).sum().item()\n",
    "#         total_samples += labels.size(0)\n",
    "\n",
    "#     avg_loss = total_loss / len(dataloader)\n",
    "#     accuracy = correct / total_samples * 100\n",
    "#     return avg_loss, accuracy\n",
    "\n",
    "# # Validation Function with Entropy Evaluation\n",
    "# def validate_model_with_entropy(model, dataloader, criterion, device, entropy_threshold=0.5):\n",
    "#     \"\"\"\n",
    "#     Evaluates the model and calculates accuracy for low-entropy and high-entropy samples.\n",
    "    \n",
    "#     Args:\n",
    "#         model: PyTorch model.\n",
    "#         dataloader: DataLoader for validation/test data.\n",
    "#         criterion: Loss function.\n",
    "#         device: 'cuda' or 'cpu'.\n",
    "#         entropy_threshold: Threshold to separate low-entropy and high-entropy samples.\n",
    "\n",
    "#     Returns:\n",
    "#         avg_loss: Average loss over all validation data.\n",
    "#         accuracy: Overall accuracy.\n",
    "#         low_entropy_accuracy: Accuracy for low-entropy samples.\n",
    "#         high_entropy_accuracy: Accuracy for high-entropy samples.\n",
    "#         low_entropy_count: Total number of low-entropy samples.\n",
    "#         high_entropy_count: Total number of high-entropy samples.\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     total_loss = 0\n",
    "#     correct = 0\n",
    "#     total_samples = 0\n",
    "\n",
    "#     # Low and high entropy tracking\n",
    "#     low_entropy_correct = 0\n",
    "#     low_entropy_total = 0\n",
    "#     high_entropy_correct = 0\n",
    "#     high_entropy_total = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for images, labels in tqdm(dataloader, desc=\"Validating\", leave=False):\n",
    "#             images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "#             # Forward pass\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # Entropy calculation\n",
    "#             entropy = calculate_entropy(outputs)\n",
    "#             low_entropy_mask = entropy < entropy_threshold\n",
    "#             high_entropy_mask = entropy >= entropy_threshold\n",
    "\n",
    "#             # Metrics for all samples\n",
    "#             total_loss += loss.item()\n",
    "#             _, preds = torch.max(outputs, dim=1)\n",
    "#             correct += (preds == labels).sum().item()\n",
    "#             total_samples += labels.size(0)\n",
    "\n",
    "#             # Metrics for low-entropy samples\n",
    "#             if low_entropy_mask.sum() > 0:\n",
    "#                 low_entropy_preds = preds[low_entropy_mask]\n",
    "#                 low_entropy_labels = labels[low_entropy_mask]\n",
    "#                 low_entropy_correct += (low_entropy_preds == low_entropy_labels).sum().item()\n",
    "#                 low_entropy_total += low_entropy_labels.size(0)\n",
    "\n",
    "#             # Metrics for high-entropy samples\n",
    "#             if high_entropy_mask.sum() > 0:\n",
    "#                 high_entropy_preds = preds[high_entropy_mask]\n",
    "#                 high_entropy_labels = labels[high_entropy_mask]\n",
    "#                 high_entropy_correct += (high_entropy_preds == high_entropy_labels).sum().item()\n",
    "#                 high_entropy_total += high_entropy_labels.size(0)\n",
    "\n",
    "#     # Calculate metrics\n",
    "#     avg_loss = total_loss / len(dataloader)\n",
    "#     accuracy = correct / total_samples * 100\n",
    "#     low_entropy_accuracy = (low_entropy_correct / low_entropy_total * 100) if low_entropy_total > 0 else 0\n",
    "#     high_entropy_accuracy = (high_entropy_correct / high_entropy_total * 100) if high_entropy_total > 0 else 0\n",
    "\n",
    "#     return avg_loss, accuracy, low_entropy_accuracy, high_entropy_accuracy, low_entropy_total, high_entropy_total\n",
    "\n",
    "def train_model(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "        images = batch['image'].to(device)   # Access 'image' key\n",
    "        labels = batch['label'].to(device)   # Access 'label' key\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Metrics\n",
    "        total_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total_samples * 100\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def validate_model_with_entropy(model, dataloader, criterion, device, entropy_threshold=0.5):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    low_entropy_correct = 0\n",
    "    low_entropy_total = 0\n",
    "    high_entropy_correct = 0\n",
    "    high_entropy_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Validating\", leave=False):\n",
    "            images = batch['image'].to(device)  # Access 'image' key\n",
    "            labels = batch['label'].to(device)  # Access 'label' key\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Entropy calculation\n",
    "            entropy = calculate_entropy(outputs)\n",
    "            low_entropy_mask = entropy < entropy_threshold\n",
    "            high_entropy_mask = entropy >= entropy_threshold\n",
    "\n",
    "            # Metrics for all samples\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            # Metrics for low-entropy samples\n",
    "            if low_entropy_mask.sum() > 0:\n",
    "                low_entropy_preds = preds[low_entropy_mask]\n",
    "                low_entropy_labels = labels[low_entropy_mask]\n",
    "                low_entropy_correct += (low_entropy_preds == low_entropy_labels).sum().item()\n",
    "                low_entropy_total += low_entropy_labels.size(0)\n",
    "\n",
    "            # Metrics for high-entropy samples\n",
    "            if high_entropy_mask.sum() > 0:\n",
    "                high_entropy_preds = preds[high_entropy_mask]\n",
    "                high_entropy_labels = labels[high_entropy_mask]\n",
    "                high_entropy_correct += (high_entropy_preds == high_entropy_labels).sum().item()\n",
    "                high_entropy_total += high_entropy_labels.size(0)\n",
    "\n",
    "    # Calculate metrics\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total_samples * 100\n",
    "    low_entropy_accuracy = (low_entropy_correct / low_entropy_total * 100) if low_entropy_total > 0 else 0\n",
    "    high_entropy_accuracy = (high_entropy_correct / high_entropy_total * 100) if high_entropy_total > 0 else 0\n",
    "\n",
    "    return avg_loss, accuracy, low_entropy_accuracy, high_entropy_accuracy, low_entropy_total, high_entropy_total\n",
    "\n",
    "\n",
    "# Fine-tuning Function\n",
    "def finetune_model_with_entropy(model, train_loader, val_loader, optimizer, criterion, device, epochs=5, entropy_threshold=0.5):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        \n",
    "        # Training step\n",
    "        train_loss, train_acc = train_model(model, train_loader, optimizer, criterion, device)\n",
    "        \n",
    "        # Validation step\n",
    "        val_loss, val_acc, low_entropy_acc, high_entropy_acc, low_entropy_count, high_entropy_count = validate_model_with_entropy(\n",
    "            model, val_loader, criterion, device, entropy_threshold\n",
    "        )\n",
    "\n",
    "        # Print results\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Val Accuracy: {val_acc:.2f}%\")\n",
    "        print(f\"Low-Entropy Sample Accuracy: {low_entropy_acc:.2f}% | Samples: {low_entropy_count}\")\n",
    "        print(f\"High-Entropy Sample Accuracy: {high_entropy_acc:.2f}% | Samples: {high_entropy_count}\\n\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m\n\u001b[1;32m      6\u001b[0m entropy_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m  \u001b[38;5;66;03m# Set the threshold for low-entropy samples\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# alpha = 0.5\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# beta = 0.5\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Fine-tune the model and evaluate entropy\u001b[39;00m\n\u001b[1;32m     12\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m finetune_model_with_entropy(\n\u001b[0;32m---> 13\u001b[0m     model, \u001b[43mtrain_loader\u001b[49m, test_loader, optimizer, criterion, device, epochs, entropy_threshold\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "model = BaseModel(n_class=10).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 5\n",
    "entropy_threshold = 0.5  # Set the threshold for low-entropy samples\n",
    "\n",
    "# alpha = 0.5\n",
    "# beta = 0.5\n",
    "\n",
    "# Fine-tune the model and evaluate entropy\n",
    "trained_model = finetune_model_with_entropy(\n",
    "    model, train_loader, test_loader, optimizer, criterion, device, epochs, entropy_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Office-31 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_path: OFFICE31/amazon\n",
      "webcam_path: OFFICE31/webcam\n",
      "dslr_path: OFFICE31/dslr\n",
      "amazon_loader size: 45\n",
      "webcam_loader size: 12\n",
      "dslr_loader size: 7\n"
     ]
    }
   ],
   "source": [
    "data_path = 'OFFICE31'\n",
    "amazon_path = os.path.join(data_path, 'amazon')\n",
    "webcam_path = os.path.join(data_path, 'webcam')\n",
    "dslr_path = os.path.join(data_path, 'dslr')\n",
    "\n",
    "print('amazon_path:', amazon_path)\n",
    "print('webcam_path:', webcam_path)\n",
    "print('dslr_path:', dslr_path)\n",
    "\n",
    "def load_data(root_path, domain, batch_size, phase):\n",
    "    transform_dict = {\n",
    "        'src': transforms.Compose(\n",
    "        [transforms.RandomResizedCrop(224),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225]),\n",
    "         ]),\n",
    "        'tar': transforms.Compose(\n",
    "        [transforms.Resize(224),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225]),\n",
    "         ])}\n",
    "    data = datasets.ImageFolder(root=os.path.join(root_path, domain), transform=transform_dict[phase])\n",
    "    data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=phase=='src', drop_last=phase=='tar', num_workers=4)\n",
    "    return data_loader\n",
    "\n",
    "amazon_loader = load_data(data_path, 'amazon', 64, 'src')\n",
    "webcam_loader = load_data(data_path, 'webcam', 64, 'tar')\n",
    "dslr_loader = load_data(data_path, 'dslr', 64, 'tar')\n",
    "\n",
    "# Checking the size of these data loaders\n",
    "print('amazon_loader size:', len(amazon_loader))\n",
    "print('webcam_loader size:', len(webcam_loader))\n",
    "print('dslr_loader size:', len(dslr_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in OFFICE-31 dataloders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3500 images from usfda_office_31_DtoA/source_images/train\n",
      "Loaded 21966 images from usfda_office_31_DtoA/target_images/train\n",
      "Loaded 73 images from usfda_office_31_DtoA/source_images/val\n",
      "Loaded 398 images from usfda_office_31_DtoA/target_images/val\n",
      "Batch Image Shape: torch.Size([64, 3, 224, 224])\n",
      "Labels Shape: torch.Size([64])\n",
      "Labels: tensor([12,  1, 10, 14,  4, 10, 18,  2,  3, 17,  8,  2,  7,  1,  3, 18,  9, 18,\n",
      "         3,  1, 10, 15,  1,  0, 15,  9,  3,  5, 15, 10, 18, 15, 18, 18, 13,  2,\n",
      "        12,  4,  7,  6, 10, 18,  3,  4,  7,  9,  9,  6, 14, 10, 15, 11,  4, 14,\n",
      "         8, 15,  0, 10, 16,  3, 18,  9, 19, 19])\n"
     ]
    }
   ],
   "source": [
    "from data_loader import Office31Dataset\n",
    "\n",
    "data_path = 'usfda_office_31_DtoA'\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "source_train_dataset = Office31Dataset(root_dir=data_path, split='train', domain='source', transform=transform)\n",
    "target_train_dataset = Office31Dataset(root_dir=data_path, split='train', domain='target', transform=transform)\n",
    "source_val_dataset = Office31Dataset(root_dir=data_path, split='val', domain='source', transform=transform)\n",
    "target_val_dataset = Office31Dataset(root_dir=data_path, split='val', domain='target', transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "source_train_loader = DataLoader(source_train_dataset, batch_size=64, shuffle=True)\n",
    "target_train_loader = DataLoader(target_train_dataset, batch_size=64, shuffle=True)\n",
    "source_val_loader = DataLoader(source_val_dataset, batch_size=64, shuffle=False)\n",
    "target_val_loader = DataLoader(target_val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "# Test the DataLoader\n",
    "for batch in source_train_loader:\n",
    "    images = batch['image']   # Shape: (32, 3, 224, 224)\n",
    "    labels = batch['label']   # Shape: (32,)\n",
    "    filenames = batch['filename']\n",
    "    print(f\"Batch Image Shape: {images.shape}\")\n",
    "    print(f\"Labels Shape: {labels.shape}\")\n",
    "    print(f\"Labels: {labels}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4119 | Train Accuracy: 90.97%\n",
      "Val Loss: 3.9939 | Val Accuracy: 22.86%\n",
      "Low-Entropy Sample Accuracy: 45.78% | Samples: 83\n",
      "High-Entropy Sample Accuracy: 16.83% | Samples: 315\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0743 | Train Accuracy: 98.06%\n",
      "Val Loss: 5.6084 | Val Accuracy: 9.55%\n",
      "Low-Entropy Sample Accuracy: 13.29% | Samples: 158\n",
      "High-Entropy Sample Accuracy: 7.08% | Samples: 240\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m entropy_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m  \u001b[38;5;66;03m# Set the threshold for low-entropy samples\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# amazon_dataloader = load_data(data_path, 'amazon', 64, 'src')\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# webcam_dataloader = load_data(data_path, 'webcam', 64, 'tar')\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Fine-tune the model and evaluate entropy\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mfinetune_model_with_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_val_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentropy_threshold\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 202\u001b[0m, in \u001b[0;36mfinetune_model_with_entropy\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, device, epochs, entropy_threshold)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# Training step\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# Validation step\u001b[39;00m\n\u001b[1;32m    205\u001b[0m val_loss, val_acc, low_entropy_acc, high_entropy_acc, low_entropy_count, high_entropy_count \u001b[38;5;241m=\u001b[39m validate_model_with_entropy(\n\u001b[1;32m    206\u001b[0m     model, val_loader, criterion, device, entropy_threshold\n\u001b[1;32m    207\u001b[0m )\n",
      "Cell \u001b[0;32mIn[16], line 124\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m    121\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)   \u001b[38;5;66;03m# Access 'label' key\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/resnet.py:276\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[0;32m--> 276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    279\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torchvision/models/resnet.py:146\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    144\u001b[0m     identity \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m--> 146\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m    148\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = BaseModel(n_class=31).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 5\n",
    "entropy_threshold = 0.5  # Set the threshold for low-entropy samples\n",
    "\n",
    "# amazon_dataloader = load_data(data_path, 'amazon', 64, 'src')\n",
    "# webcam_dataloader = load_data(data_path, 'webcam', 64, 'tar')\n",
    "\n",
    "# Fine-tune the model and evaluate entropy\n",
    "trained_model = finetune_model_with_entropy(\n",
    "    model, source_train_loader, target_val_loader, optimizer, criterion, device, epochs, entropy_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Office-31 experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A -> W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9858 | Train Accuracy: 48.28%\n",
      "Val Loss: 3.3646 | Val Accuracy: 22.01%\n",
      "Low-Entropy Sample Accuracy: 36.84% | Samples: 95\n",
      "High-Entropy Sample Accuracy: 19.91% | Samples: 673\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3434 | Train Accuracy: 64.54%\n",
      "Val Loss: 2.7813 | Val Accuracy: 24.35%\n",
      "Low-Entropy Sample Accuracy: 77.14% | Samples: 35\n",
      "High-Entropy Sample Accuracy: 21.83% | Samples: 733\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2127 | Train Accuracy: 68.09%\n",
      "Val Loss: 3.0010 | Val Accuracy: 26.69%\n",
      "Low-Entropy Sample Accuracy: 89.66% | Samples: 29\n",
      "High-Entropy Sample Accuracy: 24.22% | Samples: 739\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0146 | Train Accuracy: 73.66%\n",
      "Val Loss: 2.6660 | Val Accuracy: 32.55%\n",
      "Low-Entropy Sample Accuracy: 73.81% | Samples: 42\n",
      "High-Entropy Sample Accuracy: 30.17% | Samples: 726\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9049 | Train Accuracy: 75.93%\n",
      "Val Loss: 2.9777 | Val Accuracy: 25.52%\n",
      "Low-Entropy Sample Accuracy: 84.00% | Samples: 50\n",
      "High-Entropy Sample Accuracy: 21.45% | Samples: 718\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model = BaseModel(n_class=31).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 5\n",
    "entropy_threshold = 0.5  # Set the threshold for low-entropy samples\n",
    "\n",
    "amazon_dataloader = load_data(data_path, 'amazon', 64, 'src')\n",
    "webcam_dataloader = load_data(data_path, 'webcam', 64, 'tar')\n",
    "\n",
    "# Fine-tune the model and evaluate entropy\n",
    "trained_model = finetune_model_with_entropy(\n",
    "    model, amazon_dataloader, webcam_dataloader, optimizer, criterion, device, epochs, entropy_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A -> D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.0550 | Train Accuracy: 46.22%\n",
      "Val Loss: 2.3619 | Val Accuracy: 37.28%\n",
      "Low-Entropy Sample Accuracy: 75.00% | Samples: 56\n",
      "High-Entropy Sample Accuracy: 31.89% | Samples: 392\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3697 | Train Accuracy: 65.50%\n",
      "Val Loss: 2.4366 | Val Accuracy: 39.29%\n",
      "Low-Entropy Sample Accuracy: 68.57% | Samples: 70\n",
      "High-Entropy Sample Accuracy: 33.86% | Samples: 378\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1047 | Train Accuracy: 69.44%\n",
      "Val Loss: 2.6677 | Val Accuracy: 33.04%\n",
      "Low-Entropy Sample Accuracy: 72.55% | Samples: 51\n",
      "High-Entropy Sample Accuracy: 27.96% | Samples: 397\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0382 | Train Accuracy: 71.35%\n",
      "Val Loss: 2.3513 | Val Accuracy: 40.40%\n",
      "Low-Entropy Sample Accuracy: 78.02% | Samples: 91\n",
      "High-Entropy Sample Accuracy: 30.81% | Samples: 357\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9125 | Train Accuracy: 75.97%\n",
      "Val Loss: 2.7853 | Val Accuracy: 32.37%\n",
      "Low-Entropy Sample Accuracy: 78.08% | Samples: 73\n",
      "High-Entropy Sample Accuracy: 23.47% | Samples: 375\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model = BaseModel(n_class=31).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 5\n",
    "entropy_threshold = 0.5  # Set the threshold for low-entropy samples\n",
    "\n",
    "amazon_dataloader = load_data(data_path, 'amazon', 64, 'src')\n",
    "dslr_dataloader = load_data(data_path, 'dslr', 64, 'tar')\n",
    "\n",
    "# Fine-tune the model and evaluate entropy\n",
    "trained_model = finetune_model_with_entropy(\n",
    "    model, amazon_dataloader, dslr_dataloader, optimizer, criterion, device, epochs, entropy_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W -> A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.3140 | Train Accuracy: 48.30%\n",
      "Val Loss: 4.4856 | Val Accuracy: 23.69%\n",
      "Low-Entropy Sample Accuracy: 37.05% | Samples: 691\n",
      "High-Entropy Sample Accuracy: 19.34% | Samples: 2125\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7477 | Train Accuracy: 80.50%\n",
      "Val Loss: 4.5420 | Val Accuracy: 18.68%\n",
      "Low-Entropy Sample Accuracy: 29.47% | Samples: 587\n",
      "High-Entropy Sample Accuracy: 15.84% | Samples: 2229\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5360 | Train Accuracy: 84.91%\n",
      "Val Loss: 3.4547 | Val Accuracy: 27.66%\n",
      "Low-Entropy Sample Accuracy: 51.32% | Samples: 569\n",
      "High-Entropy Sample Accuracy: 21.67% | Samples: 2247\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5190 | Train Accuracy: 85.53%\n",
      "Val Loss: 2.9769 | Val Accuracy: 29.55%\n",
      "Low-Entropy Sample Accuracy: 76.03% | Samples: 292\n",
      "High-Entropy Sample Accuracy: 24.17% | Samples: 2524\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3927 | Train Accuracy: 89.06%\n",
      "Val Loss: 3.7211 | Val Accuracy: 25.28%\n",
      "Low-Entropy Sample Accuracy: 42.93% | Samples: 580\n",
      "High-Entropy Sample Accuracy: 20.71% | Samples: 2236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model = BaseModel(n_class=31).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 5\n",
    "entropy_threshold = 0.5  # Set the threshold for low-entropy samples\n",
    "\n",
    "webcam_dataloader = load_data(data_path, 'webcam', 64, 'src')\n",
    "amazon_dataloader = load_data(data_path, 'amazon', 64, 'tar')\n",
    "\n",
    "# Fine-tune the model and evaluate entropy\n",
    "trained_model = finetune_model_with_entropy(\n",
    "    model, webcam_dataloader, amazon_dataloader, optimizer, criterion, device, epochs, entropy_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W -> D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.2908 | Train Accuracy: 45.16%\n",
      "Val Loss: 1.9336 | Val Accuracy: 58.04%\n",
      "Low-Entropy Sample Accuracy: 71.64% | Samples: 201\n",
      "High-Entropy Sample Accuracy: 46.96% | Samples: 247\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8020 | Train Accuracy: 78.74%\n",
      "Val Loss: 0.8835 | Val Accuracy: 72.54%\n",
      "Low-Entropy Sample Accuracy: 90.27% | Samples: 226\n",
      "High-Entropy Sample Accuracy: 54.50% | Samples: 222\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5637 | Train Accuracy: 84.78%\n",
      "Val Loss: 1.0540 | Val Accuracy: 70.76%\n",
      "Low-Entropy Sample Accuracy: 90.62% | Samples: 224\n",
      "High-Entropy Sample Accuracy: 50.89% | Samples: 224\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4006 | Train Accuracy: 89.31%\n",
      "Val Loss: 0.7178 | Val Accuracy: 80.13%\n",
      "Low-Entropy Sample Accuracy: 96.88% | Samples: 224\n",
      "High-Entropy Sample Accuracy: 63.39% | Samples: 224\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3804 | Train Accuracy: 89.18%\n",
      "Val Loss: 0.6548 | Val Accuracy: 80.13%\n",
      "Low-Entropy Sample Accuracy: 94.58% | Samples: 240\n",
      "High-Entropy Sample Accuracy: 63.46% | Samples: 208\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model = BaseModel(n_class=31).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 5\n",
    "entropy_threshold = 0.5  # Set the threshold for low-entropy samples\n",
    "\n",
    "webcam_dataloader = load_data(data_path, 'webcam', 64, 'src')\n",
    "dslr_dataloader = load_data(data_path, 'dslr', 64, 'tar')\n",
    "\n",
    "# Fine-tune the model and evaluate entropy\n",
    "trained_model = finetune_model_with_entropy(\n",
    "    model, webcam_dataloader, dslr_dataloader, optimizer, criterion, device, epochs, entropy_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D -> A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.7258 | Train Accuracy: 35.54%\n",
      "Val Loss: 14.9562 | Val Accuracy: 4.01%\n",
      "Low-Entropy Sample Accuracy: 7.69% | Samples: 13\n",
      "High-Entropy Sample Accuracy: 4.00% | Samples: 2803\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9414 | Train Accuracy: 78.11%\n",
      "Val Loss: 12.0211 | Val Accuracy: 7.21%\n",
      "Low-Entropy Sample Accuracy: 11.25% | Samples: 471\n",
      "High-Entropy Sample Accuracy: 6.40% | Samples: 2345\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4157 | Train Accuracy: 87.15%\n",
      "Val Loss: 3.8529 | Val Accuracy: 28.27%\n",
      "Low-Entropy Sample Accuracy: 39.20% | Samples: 574\n",
      "High-Entropy Sample Accuracy: 25.47% | Samples: 2242\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3259 | Train Accuracy: 90.36%\n",
      "Val Loss: 46.0419 | Val Accuracy: 3.91%\n",
      "Low-Entropy Sample Accuracy: 3.75% | Samples: 2720\n",
      "High-Entropy Sample Accuracy: 8.33% | Samples: 96\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3055 | Train Accuracy: 92.97%\n",
      "Val Loss: 37.3888 | Val Accuracy: 4.30%\n",
      "Low-Entropy Sample Accuracy: 4.91% | Samples: 2015\n",
      "High-Entropy Sample Accuracy: 2.75% | Samples: 801\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model = BaseModel(n_class=31).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 5\n",
    "entropy_threshold = 0.5  # Set the threshold for low-entropy samples\n",
    "\n",
    "dslr_dataloader = load_data(data_path, 'dslr', 64, 'src')\n",
    "amazon_dataloader = load_data(data_path, 'amazon', 64, 'tar')\n",
    "\n",
    "# Fine-tune the model and evaluate entropy\n",
    "trained_model = finetune_model_with_entropy(\n",
    "    model, dslr_dataloader, amazon_dataloader, optimizer, criterion, device, epochs, entropy_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D -> W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.6948 | Train Accuracy: 38.35%\n",
      "Val Loss: 3.5691 | Val Accuracy: 35.55%\n",
      "Low-Entropy Sample Accuracy: 68.25% | Samples: 211\n",
      "High-Entropy Sample Accuracy: 23.16% | Samples: 557\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0607 | Train Accuracy: 78.11%\n",
      "Val Loss: 1.6099 | Val Accuracy: 55.73%\n",
      "Low-Entropy Sample Accuracy: 78.55% | Samples: 275\n",
      "High-Entropy Sample Accuracy: 43.00% | Samples: 493\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4581 | Train Accuracy: 87.75%\n",
      "Val Loss: 1.1796 | Val Accuracy: 67.19%\n",
      "Low-Entropy Sample Accuracy: 88.00% | Samples: 300\n",
      "High-Entropy Sample Accuracy: 53.85% | Samples: 468\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2722 | Train Accuracy: 93.17%\n",
      "Val Loss: 1.7352 | Val Accuracy: 52.86%\n",
      "Low-Entropy Sample Accuracy: 86.27% | Samples: 153\n",
      "High-Entropy Sample Accuracy: 44.55% | Samples: 615\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3821 | Train Accuracy: 90.16%\n",
      "Val Loss: 1.8397 | Val Accuracy: 55.60%\n",
      "Low-Entropy Sample Accuracy: 81.01% | Samples: 258\n",
      "High-Entropy Sample Accuracy: 42.75% | Samples: 510\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model = BaseModel(n_class=31).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 5\n",
    "entropy_threshold = 0.5  # Set the threshold for low-entropy samples\n",
    "\n",
    "dslr_dataloader = load_data(data_path, 'dslr', 64, 'src')\n",
    "webcam_dataloader = load_data(data_path, 'webcam', 64, 'tar')\n",
    "\n",
    "# Fine-tune the model and evaluate entropy\n",
    "trained_model = finetune_model_with_entropy(\n",
    "    model, dslr_dataloader, webcam_dataloader, optimizer, criterion, device, epochs, entropy_threshold\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
